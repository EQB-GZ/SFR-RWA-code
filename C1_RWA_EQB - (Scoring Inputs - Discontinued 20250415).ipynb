{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2754a081",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f46fdf8-effa-48f5-99f0-ee81fb3836a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import SFR_PD_Recalibration_2023_Lib as tool\n",
    "# import Concentra_SFR_Fit_for_Use_2024_Lib as lib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import Lib_RWA as Lib_RWA\n",
    "\n",
    "# delete lib_RWA from system modules \n",
    "\n",
    "del(sys.modules['Lib_RWA'])\n",
    "\n",
    "# delete SFR_PD_Recalibration_2023_Lib from system modules\n",
    "\n",
    "del(sys.modules['SFR_PD_Recalibration_2023_Lib'])\n",
    "\n",
    "\n",
    "import SFR_PD_Recalibration_2023_Lib as tool\n",
    "\n",
    "import Lib_RWA as Lib_RWA\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bf9d4f-975b-42ad-b7c5-c42d70b7b5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900054f9",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae55b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Snaphsot and RWA file information\n",
    "\n",
    "# snapshot_num = 202212 # 20250403 Fran commented out as George in S1\n",
    "# snapshot = str(snapshot_num) # 20250403 Fran commented out as George in S1\n",
    "# snapshot_date = '2022-12-31' # 20250403 Fran commented out as George in S1\n",
    "# RWA_File_from_Chenxi = 'SFR_RWA_202212.csv' #20250403 Fran added as George S1!!! Note to be consistent with the snapshot date\n",
    "\n",
    "snapshot_num = 202412 # 20250403 Fran added as George in S1 \n",
    "snapshot = str(snapshot_num) # 20250403 Fran added as George in S1\n",
    "snapshot_date = '2024-12-31' # 20250403 Fran added as George in S1\n",
    "RWA_File_from_Chenxi = 'SFR_202412_v2 (from Chenxi 20250403).csv' #20250403 Fran added as George S1!!! Note to be consistent with the snapshot date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669d81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAR 2023 Ch5 prescribed parameters\n",
    "\n",
    "correlation_residential_mortgages = 0.15\n",
    "correlation_residential_mortgages_rental = 0.22\n",
    "\n",
    "CMHC_pd = 0.0001\n",
    "CMHC_lgd = 0.11 #according to the newly developed Sovereign LGD model\n",
    "\n",
    "lgd_gen_floor = 0.1 #general floor by CAR 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to Keep\n",
    "\n",
    "RWA_Info_Cols_to_Keep = ['Loan_Number','Insured_class','EAD','Advance_Amount','Years_to_maturity', 'corr_uninsured', 'RWA_standardized']\n",
    "\n",
    "PD_Cols_to_Keep = ['Loan_Number','SL_Date','PD_Pre_MOC','PD_Post_MOC_Pre_Adj','PD_Post_MOC','MRS_Bin_PD','Insured_Ind','Alt_Prime_Indicator','RemainingPrincipal_Tot_Exp','RemainingPrincipal_Excl_Partner', 'Corporate_Applicant_Ind','Combo_Province_Metro_Override','Combo_Province_Metro_Override_WOE', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE','Beacon_Avg_App_CoApp','Beacon_Avg_App_CoApp_WOE','BF_LTV_Tot_Exp_FSA_Dw_WF','Combo_LTV_Insured_Ind','Combo_LTV_Insured_Ind_WOE']\n",
    "\n",
    "PD_Cols_for_Corp = ['AdvancedAmount_EQB_Exp','AdvancedAmount_Total_Exp','AdvancedAmt_Incl_Part','AdvancedAmt_Excl_Part','Remaining_Term'] \n",
    "\n",
    "\n",
    "LGD_Cols_to_Keep = ['Loan_Number','MRS_Bin_LGD','LR_Avg_LGD','Segment_Avg_LGD','Base_Line_LGD','LGD_DT_Adjusted','Model_LGD','Sub_Product','BF_Appr_Prov_Dw','Appraisal_Bin_WOE', 'Occupancy', 'Occupancy_WOE', 'Province_Foreclosure', 'Province_Foreclosure_WOE', 'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw','LTV_Bin_WOE' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58667db5",
   "metadata": {},
   "source": [
    "# Set Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc94526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "\n",
    "current_dir = os.getcwd()  # 20250403 George added\n",
    "\n",
    "# code_dir= \"C:\\\\Users\" +'\\\\' + username + '\\\\' + \"Equitable Bank\\\\EQB-Concentra Fit for Use - Fit_for_Use Development - Fit_for_Use Development\\\\RWA\\\\code\" # 20250403 George commented out Francesca/Joseph's code\n",
    "\n",
    "code_dir = current_dir # 20250403 George added\n",
    "\n",
    "\n",
    "if int(snapshot_num) == 202412:\n",
    "    input_dir = code_dir + '\\\\..\\\\' + \"Inputs\" # 20250406 George added\n",
    "    Output_dir = code_dir + '\\\\..\\\\' + \"Outputs\" #20250406 George added\n",
    "\n",
    "if int(snapshot_num) == 202212:\n",
    "    input_dir = code_dir + '\\\\..\\\\' + \"Dec. 2022 RWA Inputs\" #20250410 George added\n",
    "    Output_dir = code_dir + '\\\\..\\\\' + \"Replicated Dec 2022 Outputs\" #20250410 George added\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043d70e",
   "metadata": {},
   "source": [
    "# Load RWA Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be05664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in the RWA data from Chenxi\n",
    "\n",
    "# Import data with Loan_Number,Insured_class,CalibratedPD,Final_LGD,EAD,Advance_Amount,Years_to_maturity and corr_uninsured\n",
    "##################### load snapshot data Chenxi provided and rename#################################\n",
    "#rwa_data = pd.read_csv(input_dir +'\\\\'+'SFR_RWA_' + snapshot + '.csv', low_memory=False) #20250403 Fran commented as George in S1\n",
    "rwa_data = pd.read_csv(input_dir +'\\\\'+ RWA_File_from_Chenxi, low_memory=False) #20250403 Fran added as George in S1\n",
    "\n",
    "rwa_raw_data_0 = rwa_data[RWA_Info_Cols_to_Keep]  # 20250410 George add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234a3eed-406c-40d3-9494-5559c65cf8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53402, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ce0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Floor the EAD on 0          \n",
    "\n",
    "rwa_raw_data_0.loc[rwa_raw_data_0['EAD']<0, ['EAD']] =0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40eb94",
   "metadata": {},
   "source": [
    "# Load PD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e73271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new SFR PD model generated PD \n",
    "\n",
    "#new_pd_data = pd.read_csv( Active_dir +'\\\\'+'PARAM_Pred_PD'  + '.csv', low_memory=False) # 20250402 George Commented out \n",
    "new_pd_data = pd.read_pickle(input_dir + '\\\\Rating_July2020_to_Dec2024_EQB (from George 20250414).pkl') # 20250402 George added\n",
    "new_pd_data_red = new_pd_data.loc[new_pd_data['SL_Date'] == snapshot_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d53a92c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIRB_PD_Risk_Rating', 'AdvancedAmount_EQB_Exp', 'AdvancedAmount_Total_Exp', 'AdvancedAmt_Excl_Part', 'AdvancedAmt_Incl_Part', 'Alt_Prime_Indicator', 'AppraisalValue_Inception', 'BF_LTV_Tot_Exp_FSA_Dw_WF', 'Beacon_Avg_App_CoApp', 'Beacon_Avg_App_CoApp_WOE', 'City', 'Combo_LTV_Insured_Ind', 'Combo_LTV_Insured_Ind_WOE', 'Combo_Province_Metro_Override', 'Combo_Province_Metro_Override_WOE', 'Corporate_Applicant_Ind', 'Delinquency_Status_Adj', 'Dwelling_Type', 'FSA', 'Funded_Date', 'Insured_Ind', 'LoanType', 'Loan_Number', 'Metro_Region_BF_FMT', 'PD_Post_MOC', 'PD_Pre_MOC', 'PD_scoring', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE', 'Province', 'RemainingPrincipal_Excl_Partner', 'RemainingPrincipal_Tot_Exp', 'Remaining_Term', 'SL_Date', 'Sub_Product', 'log_odds']\n"
     ]
    }
   ],
   "source": [
    "# print columns in alphabetical order in the new_pd_data_red dataframe #20250402 George added\n",
    "\n",
    "print(sorted(new_pd_data_red.columns)) #20250402 George added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc43118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_28156\\1440374422.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_pd_data_red['PD_Post_MOC_Pre_Adj'] = np.nan #20250402 George added\n"
     ]
    }
   ],
   "source": [
    "# For columns PD_Post_MOC_Pre_Adj and PD_Pre_MOC, if not in the data set, add them with nan #20250402 George added\n",
    "\n",
    "if 'PD_Post_MOC_Pre_Adj' not in new_pd_data_red.columns: #20250402 George added\n",
    "\n",
    "    new_pd_data_red['PD_Post_MOC_Pre_Adj'] = np.nan #20250402 George added\n",
    "\n",
    "if 'PD_Pre_MOC' not in new_pd_data_red.columns: #20250402 George added\n",
    "\n",
    "    new_pd_data_red['PD_Pre_MOC'] = np.nan #20250402 George added\n",
    "\n",
    "\n",
    "# Rename AIRB_PD_Risk_Rating to be MRS_Bin #20250402 George added\n",
    "\n",
    "new_pd_data_red = new_pd_data_red.rename({'AIRB_PD_Risk_Rating':'MRS_Bin'}, axis='columns')  #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd62f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loan number list for Chenxi as she requested to check\n",
    "with pd.ExcelWriter(Output_dir +'\\\\'+'eqb_loans_list_dec24.xlsx' )as writer:\n",
    "    new_pd_data_red['Loan_Number'].to_excel(writer, sheet_name='loan_list', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f38a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Checking Default Loans *****************\n",
      "  MRS_Bin Loan_Number PD_Post_MOC          \n",
      "              nunique         min       max\n",
      "0     1.0       26705    0.002228  0.002228\n",
      "1     2.0       14383    0.003622  0.003622\n",
      "2     3.0        5505    0.007377  0.007377\n",
      "3     4.0        3148    0.011499  0.011499\n",
      "4     5.0        1751    0.019067  0.019067\n",
      "5     6.0        1765    0.034554  0.034554\n",
      "6     7.0        1588    0.107857  0.107857\n",
      "7     8.0         402    0.629118  0.629118\n",
      "8     9.0         382    1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Group by MRS_Bin, count distinct Loan_Number and min and max of PD_Post_MOC #20250402 George added\n",
    "print('***************Checking Default Loans *****************') #20250402 George added\n",
    "print(new_pd_data_red.groupby(['MRS_Bin'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'PD_Post_MOC': [min, max]})) #20250402 George added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0933d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Dafault Loans\n",
    "\n",
    "# # Remove rows with PD_Post_MOC <=0 or >=1 (defaults) #20250402 George added\n",
    "\n",
    "# new_pd_data_red = new_pd_data_red.loc[(new_pd_data_red['PD_Post_MOC'] > 0) & (new_pd_data_red['PD_Post_MOC'] < 1)] #20250402 George added\n",
    "\n",
    "# # Group by MRS_Bin, count distinct Loan_Number and min and max of PD_Post_MOC #20250402 George added\n",
    "\n",
    "# print('***************After Removing Default Loans*****************') #20250402 George added\n",
    "\n",
    "# print(new_pd_data_red.groupby(['MRS_Bin'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'PD_Post_MOC': [min, max]})) #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e384187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "\n",
    "new_pd_data_red.rename({'MRS_Bin':'MRS_Bin_PD'}, axis = 'columns', inplace=True) #20250412 George added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf053e",
   "metadata": {},
   "source": [
    "## Check Corporate Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246152fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Group by SL_Date and Corporate_Applicant_Ind*****************\n",
      "     SL_Date  Corporate_Applicant_Ind  Loan_Number\n",
      "0 2024-12-31                      0.0        54203\n",
      "1 2024-12-31                      1.0         1426\n"
     ]
    }
   ],
   "source": [
    "# Group by SL_Date and Corporate_Applicant_Ind, count number of Loan_Number\n",
    "\n",
    "print('***************Group by SL_Date and Corporate_Applicant_Ind*****************') #20250403 George added\n",
    "\n",
    "print(new_pd_data_red.groupby(['SL_Date','Corporate_Applicant_Ind'], as_index=False).agg({'Loan_Number': pd.Series.nunique})) #20250403 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346c774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Group by merge_ and Corporate_Applicant_Ind*****************\n",
      "                                              Loan_Number\n",
      "merge_               Corporate_Applicant_Ind             \n",
      "Loan in Chenxi only  NaN                             30.0\n",
      "                     0.0                              NaN\n",
      "                     1.0                              NaN\n",
      "Loan in PD Data only NaN                              NaN\n",
      "                     0.0                            834.0\n",
      "                     1.0                           1423.0\n",
      "Loan in both         NaN                              NaN\n",
      "                     0.0                          53369.0\n",
      "                     1.0                              3.0\n"
     ]
    }
   ],
   "source": [
    "# Compare with RWA data from Chenxi\n",
    "\n",
    "# Outer Join new_pd_data_red with rwa_raw_data_0 on Loan_Number #20250403 George added\n",
    "\n",
    "rwa_raw_data_pd_check = pd.merge(rwa_raw_data_0['Loan_Number'], new_pd_data_red[['Loan_Number','Corporate_Applicant_Ind']], how='outer', on=['Loan_Number'], indicator= 'merge_') #20250403 George added\n",
    "\n",
    "# change the content to be more meaningful #20250403 George added\n",
    "\n",
    "rwa_raw_data_pd_check['merge_'] = rwa_raw_data_pd_check['merge_'].replace({'left_only': 'Loan in Chenxi only', 'right_only': 'Loan in PD Data only', 'both': 'Loan in both'}) #20250403 George added\n",
    "\n",
    "\n",
    "# group by merge_ and Corporate_Applicant_Ind, including missing values, count number of Loan_Number #20250403 George added\n",
    "\n",
    "print('***************Group by merge_ and Corporate_Applicant_Ind*****************') #20250403 George added\n",
    "\n",
    "print(rwa_raw_data_pd_check.groupby(['merge_','Corporate_Applicant_Ind'], dropna= False).agg({'Loan_Number': pd.Series.nunique})) #20250403 George added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbc5c1",
   "metadata": {},
   "source": [
    "# Load LGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8bdb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new SFR LGD model generated LGD and apply LGD floor \n",
    "\n",
    "# 2023_11-04 is most recent one from Ben\n",
    "#new_lgd_data = pd.read_csv(input_dir+'\\Dec_2022_LGD_2023_11_04_Recalibrated_Model.csv', low_memory = False)\n",
    "\n",
    "if snapshot_num == 202212:\n",
    "\n",
    "    new_lgd_data = pd.read_pickle(input_dir + '\\\\eqb_lgd_scored_2022_12 (from Abhi 20250410).pkl') # 20250406 George added\n",
    "\n",
    "if snapshot_num == 202412:\n",
    "\n",
    "    new_lgd_data = pd.read_pickle(input_dir + '\\\\eqb_lgd_scored_2024_12 (from Abhi 20250404).pkl') # 20250406 George added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "458809e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LTV_Bin_WOE', 'Appraisal_Bin_WOE']\n"
     ]
    }
   ],
   "source": [
    "# print duplicated columns \n",
    "\n",
    "print(new_lgd_data.columns[new_lgd_data.columns.duplicated()].tolist()) #20250412 George added\n",
    "\n",
    "# Remove duplicated columns \n",
    "\n",
    "new_lgd_data = new_lgd_data.loc[:,~new_lgd_data.columns.duplicated()] #20250412 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3bc8a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Appraisal_Bin', 'Appraisal_Bin_WOE', 'BF_Appr_Prov_Dw', 'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'Default_Ind', 'Final_LGD', 'Foreclosure_Ind', 'Foreclosure_Ind_WOE', 'Insured_Ind', 'LR_Avg_LGD', 'LTV_Bin', 'LTV_Bin_WOE', 'LoanType', 'Loan_Number', 'MRS_Bin', 'Mapped_LGD', 'Occupancy', 'Occupancy_WOE', 'Pred_LGD', 'Province_Foreclosure', 'Province_Foreclosure_WOE', 'RemainingPrincipal_Excl_Partner', 'SL_Date', 'Sub_Product']\n"
     ]
    }
   ],
   "source": [
    "# print columns in alphabetical order in the new_lgd_data dataframe \n",
    "\n",
    "print(sorted(new_lgd_data.columns)) #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5912ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns LGD_DT_Adjusted, Segment_Avg_LGD and Base_Line_LGD if they are not in the data set #20250412 George added\n",
    "\n",
    "if 'LGD_DT_Adjusted' not in new_lgd_data.columns: # 20250412 George added\n",
    "    new_lgd_data['LGD_DT_Adjusted'] = np.nan  # 20250412 George added, the numbers are not the latest and this will not be used in the final result\n",
    "\n",
    "if 'Segment_Avg_LGD' not in new_lgd_data.columns: # 20250412 George added, same treatment as RWA for Concentra\n",
    "    new_lgd_data['Segment_Avg_LGD'] = new_lgd_data.loc[:,'Mapped_LGD']\n",
    "\n",
    "if 'Base_Line_LGD' not in new_lgd_data.columns: # 20250412 George added, same treatment as RWA for Concentra\n",
    "    new_lgd_data['Base_Line_LGD'] = new_lgd_data.loc[:,'Mapped_LGD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68b4396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "\n",
    "new_lgd_data = new_lgd_data.rename({'MRS_Bin':'MRS_Bin_LGD','Final_LGD':'Model_LGD'}, axis = 'columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d928ea",
   "metadata": {},
   "source": [
    "# Merge PD and LGD data for Corporate Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35817064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new_Pd_data_red and new_lgd_data on Loan_Number\n",
    "\n",
    "PD_LGD_Merge = pd.merge(new_pd_data_red[PD_Cols_to_Keep + PD_Cols_for_Corp], new_lgd_data[LGD_Cols_to_Keep], how='outer', on=['Loan_Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4435b45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Corporate Loans Only*****************\n",
      "    Insured_Ind  MRS_Bin_PD  MRS_Bin_LGD  Loan_Number  RemainingPrincipal_Tot_Exp\n",
      "0   Not Insured         1.0            1          225                9.839399e+07\n",
      "1   Not Insured         1.0            2           91                4.079501e+07\n",
      "2   Not Insured         1.0            3           15                7.153886e+06\n",
      "3   Not Insured         1.0            4            1                2.092401e+05\n",
      "4   Not Insured         2.0            1          110                6.913848e+07\n",
      "5   Not Insured         2.0            2          268                1.580170e+08\n",
      "6   Not Insured         2.0            3          175                1.119233e+08\n",
      "7   Not Insured         2.0            4           69                3.055346e+07\n",
      "8   Not Insured         3.0            1           31                2.121737e+07\n",
      "9   Not Insured         3.0            2          102                6.558273e+07\n",
      "10  Not Insured         3.0            3           85                5.195284e+07\n",
      "11  Not Insured         3.0            4           22                1.014608e+07\n",
      "12  Not Insured         4.0            1           12                5.819073e+06\n",
      "13  Not Insured         4.0            2           30                1.967793e+07\n",
      "14  Not Insured         4.0            3           39                2.686038e+07\n",
      "15  Not Insured         4.0            4            9                3.126355e+06\n",
      "16  Not Insured         5.0            1            7                5.740113e+06\n",
      "17  Not Insured         5.0            2           11                8.240010e+06\n",
      "18  Not Insured         5.0            3           15                8.519018e+06\n",
      "19  Not Insured         5.0            4            6                2.192133e+06\n",
      "20  Not Insured         6.0            1            6                4.948364e+06\n",
      "21  Not Insured         6.0            2            6                3.818745e+06\n",
      "22  Not Insured         6.0            3           10                6.144046e+06\n",
      "23  Not Insured         6.0            4            7                1.685256e+06\n",
      "24  Not Insured         7.0            1            6                2.765939e+06\n",
      "25  Not Insured         7.0            2           13                1.098882e+07\n",
      "26  Not Insured         7.0            3           11                7.641777e+06\n",
      "27  Not Insured         7.0            4            6                2.542025e+06\n",
      "28  Not Insured         8.0            1            7                3.614917e+06\n",
      "29  Not Insured         8.0            2           10                7.515959e+06\n",
      "30  Not Insured         8.0            3            5                3.729701e+06\n",
      "31  Not Insured         9.0            1            1                3.255914e+05\n",
      "32  Not Insured         9.0            2            8                6.167236e+06\n",
      "33  Not Insured         9.0            3            6                5.511657e+06\n",
      "34  Not Insured         9.0            4            1                2.938532e+05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter with Corporate_Applicant_Ind = 1 #20250404 George added\n",
    "\n",
    "PD_LGD_Merge_Corp = PD_LGD_Merge.loc[PD_LGD_Merge['Corporate_Applicant_Ind'] == 1] #20250404 George added\n",
    "\n",
    "# Group by Insured_Ind, MRS_Bin_PD and MRS_Bin_LGD, count number of Loan_Number and sum of RemainginPrincipal_Tot_Exp#20250404 George added\n",
    "\n",
    "print('***************Corporate Loans Only*****************') #20250404 George added\n",
    "\n",
    "print(PD_LGD_Merge_Corp.groupby(['Insured_Ind','MRS_Bin_PD','MRS_Bin_LGD'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'RemainingPrincipal_Tot_Exp': sum})) #20250404 George added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ffe626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save data to excel #20250404 George added\n",
    "\n",
    "with pd.ExcelWriter(Output_dir +'\\\\'+'Corporate_Loans_Breakdown.xlsx' )as writer:\n",
    "\n",
    "    PD_LGD_Merge_Corp.to_excel(writer, sheet_name='Corp_Loans', index=False) #20250404 George added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e783c",
   "metadata": {},
   "source": [
    "# Merge RWA Data Info with PD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "747ffe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = new_pd_data_red[ ['PD_Pre_MOC','PD_Post_MOC_Pre_Adj','PD_Post_MOC'] ].drop_duplicates()\n",
    "\n",
    "rwa_raw_data_1 = pd.merge(rwa_raw_data_0, new_pd_data_red[PD_Cols_to_Keep], how='outer',on=['Loan_Number'], indicator= 'merge_Chenxi_PD')\n",
    "\n",
    "rwa_raw_data_1['merge_Chenxi_PD'] = rwa_raw_data_1['merge_Chenxi_PD'].replace({'left_only': 'Loan in Chenxi only', 'right_only': 'Loan in PD Data only', 'both': 'Loan in both Chenxi and PD'}) #20250403 George added\n",
    "\n",
    "# rwa_raw_data_2 =  rwa_raw_data_1.loc[~rwa_raw_data_1['PD_Pre_MOC'].isnull()] #remove records not existing in Chenxi's data since they cannot be compared\n",
    "\n",
    "rwa_raw_data_2 = rwa_raw_data_1.copy()\n",
    "\n",
    "rwa_raw_data_3 = rwa_raw_data_2.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c48f6",
   "metadata": {},
   "source": [
    "# Merge RWA info with LGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52382331-c858-42ec-9935-6cf32af56b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Gen3 LGD data, only including uninsured loans\n",
    "\n",
    "rwa_raw_data_4 = pd.merge(rwa_raw_data_3,new_lgd_data[LGD_Cols_to_Keep], how='outer', on= ['Loan_Number'], indicator= 'merge_ChenxiPD_LGD')\n",
    "\n",
    "rwa_raw_data_4['merge_ChenxiPD_LGD'] = rwa_raw_data_4['merge_ChenxiPD_LGD'].replace({'left_only': 'Loan in ChenxiPD only', 'right_only': 'Loan in LGD Data only', 'both': 'Loan in both ChenxiPD and LGD'})\n",
    "\n",
    "\n",
    "# rwa_raw_data_4 = rwa_raw_data_4.rename({'MRS_Bin':'MRS_Bin_LGD','Final_LGD':'Model_LGD'}, axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da01f",
   "metadata": {},
   "source": [
    "# Calculate RWA with 0 Addon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "954f8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Addon to be 0\n",
    "\n",
    "rwa_raw_data_0Addon = rwa_raw_data_4.copy()\n",
    "rwa_raw_data_0Addon['AddOn'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e98f4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(CMHC_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15a8e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Run RWA calculation function\n",
    "\n",
    "[df_out_0Addon, rwa_by_Insured_class_0Addon, rwa_by_MRS_Bin_0Addon, res_data_0Addon]  = Lib_RWA.rwa_calculation(df_input_data = rwa_raw_data_0Addon, lgd_gen_floor = lgd_gen_floor, CMHC_lgd = CMHC_lgd, CMHC_pd = CMHC_pd )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f467de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print duplicated columns in res_data_0Addon - These are in LGD data set\n",
    "\n",
    "print(res_data_0Addon.columns[res_data_0Addon.columns.duplicated()].tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17380f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to parquet\n",
    "\n",
    "res_data_0Addon.to_parquet(Output_dir +'\\\\'+'eqb_rwa_addon_zero.parquet', index=False)\n",
    "\n",
    "# with pd.ExcelWriter(Output_dir +'\\\\'+'eqb_rwa_addon_zero.xlsx' )as writer:\n",
    "#     res_data_0Addon.to_excel(writer, sheet_name='RWA_data', index=False)\n",
    "#     df_out_0Addon.to_excel(writer, sheet_name=\"RWA\") \n",
    "#     rwa_by_Insured_class_0Addon.to_excel(writer, sheet_name=\"rwa_by_Insured_class\")\n",
    "#     rwa_by_MRS_Bin_0Addon.to_excel(writer, sheet_name=\"rwa_by_MRS_Bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab833aa0",
   "metadata": {},
   "source": [
    "# Get LGD Addon and Calculate RWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5bd4ab4-a458-4cb5-a04b-de2df46e3b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n",
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "## retrieve DLGD floor readily available AddOn from Finance Production database\n",
    "# Get max Feedid\n",
    "server_2 = 'EQDWP01'  \n",
    "database_2 = 'ET_Finance_Production'   \n",
    "\n",
    "\n",
    "\n",
    "def sql_max_FeedID( snapshot ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_RE_log' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT max([FeedID]) as max_FeedID\n",
    "       FROM {table}\n",
    "       where Reporting_date =  {snapshot} \n",
    "             \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "Max_Feed_ID= tool.download_from_sql( server_2, database_2, sql_max_FeedID( \"'\" + snapshot_date + \"'\" ) )['max_FeedID'][0]\n",
    "\n",
    "def sql_LGD_addon( Max_Feed_ID ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_X_WoE_LGD_Result' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot_date) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "       [LoanNumber]\n",
    "       ,[Add_on_LGD] as AddOn\n",
    "       FROM {table}\n",
    "       where RunID =  {Max_Feed_ID} \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "Add_on_LGD= tool.download_from_sql( server_2, database_2, sql_LGD_addon(Max_Feed_ID) )\n",
    "\n",
    "Add_on_LGD['LoanNumber'] = Add_on_LGD['LoanNumber'].astype(str).astype(int)\n",
    "\n",
    "rwa_raw_data_TrueAddon = pd.merge(rwa_raw_data_4, Add_on_LGD, how='left', left_on= ['Loan_Number'],right_on=['LoanNumber'])\n",
    "\n",
    "\n",
    "#rwa_raw_data_5['Final_LGD'] = rwa_raw_data_5['Final_LGD_old']\n",
    "#rwa_raw_data_5['PD_Post_MOC'] = rwa_raw_data_5['CalibratedPD_old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfadc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Run RWA calculation function\n",
    "\n",
    "[df_out, rwa_by_Insured_class, rwa_by_MRS_Bin, res_data]  = Lib_RWA.rwa_calculation(rwa_raw_data_TrueAddon, lgd_gen_floor, CMHC_lgd, CMHC_pd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c3e0635-c02f-49f1-9a96-6311c38b9142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Data to Parquet file\n",
    "\n",
    "res_data.to_parquet(Output_dir +'\\\\'+'eqb_rwa_original.parquet', index=False)\n",
    "\n",
    "# with pd.ExcelWriter(Output_dir +'\\\\'+'eqb_rwa_original.xlsx' )as writer:\n",
    "#     res_data.to_excel(writer, sheet_name='RWA_Data', index=False)\n",
    "#     df_out.to_excel(writer, sheet_name=\"RWA\") \n",
    "#     rwa_by_Insured_class.to_excel(writer, sheet_name=\"rwa_by_Insured_class\")\n",
    "#     rwa_by_MRS_Bin.to_excel(writer, sheet_name=\"rwa_by_MRS_Bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80935c51",
   "metadata": {},
   "source": [
    "# Sanity Check the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9e22027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot date: 2024-12-31\n",
      "Shape of res_data: (55659, 57)\n",
      "***************Group by Insured_Indicator*****************\n",
      "  Insured_class  Loan_Number           EAD       RWA_new  RWA_Ratio\n",
      "0            CG       4534.0  1.290269e+09  9.555135e+07   0.074055\n",
      "1          CMHC      11040.0  3.061192e+09  5.133710e+07   0.016770\n",
      "2         Sagen       8832.0  2.293171e+09  1.785676e+08   0.077869\n",
      "3     Uninsured      28996.0  1.562863e+10  3.487959e+09   0.223177\n",
      "4         Total      53402.0  2.227326e+10  3.813415e+09   0.171210\n",
      "['AddOn', 'Advance_Amount', 'Alt_Prime_Indicator', 'Appraisal_Bin_WOE', 'BF_Appr_Prov_Dw', 'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'BF_LTV_Tot_Exp_FSA_Dw_WF', 'Base_Line_LGD', 'Beacon_Avg_App_CoApp', 'Beacon_Avg_App_CoApp_WOE', 'CalibratedPD', 'Combo_LTV_Insured_Ind', 'Combo_LTV_Insured_Ind_WOE', 'Combo_Province_Metro_Override', 'Combo_Province_Metro_Override_WOE', 'Corporate_Applicant_Ind', 'DLGD_floor', 'EAD', 'EAD_DLGD_Modified', 'EAD_Post_CRM', 'Final_LGD', 'Insured_Ind', 'Insured_class', 'LGD_Before_Floors', 'LGD_DT_Adjusted', 'LR_Avg_LGD', 'LTV_Bin_WOE', 'LoanNumber', 'Loan_Number', 'MRS_Bin_LGD', 'MRS_Bin_PD', 'Maturity_adj', 'Model_LGD_Modified', 'OSFI_LGD_floor', 'Occupancy', 'Occupancy_WOE', 'Pre_final_LGD', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE', 'Province_Foreclosure', 'Province_Foreclosure_WOE', 'RWA_new', 'RWA_standardized', 'RemainingPrincipal_Excl_Partner', 'RemainingPrincipal_Tot_Exp', 'SL_Date', 'Segment_Avg_LGD', 'Sub_Product', 'Years_to_maturity', 'corr_insured', 'corr_uninsured', 'deductible_amount', 'insured_PMI_ratio', 'merge_ChenxiPD_LGD', 'merge_Chenxi_PD', 'risk_weight_insured', 'risk_weight_uninsured']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_28156\\1574102103.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Sumry = Sumry.append(Sumry.sum(numeric_only=True), ignore_index=True) #20250403 George added\n"
     ]
    }
   ],
   "source": [
    "# print snapshot date \n",
    "\n",
    "print('Snapshot date: ' + snapshot_date) #20250403 George added\n",
    "\n",
    "# print the shape of res_data\n",
    "\n",
    "print('Shape of res_data: ' + str(res_data.shape)) #20250403 George added\n",
    "\n",
    "# Group by Insured_Indicator, count number of Loan_Number, sum of EAD and RWA_new\n",
    "\n",
    "print('***************Group by Insured_Indicator*****************') #20250403 George added\n",
    "\n",
    "Sumry = res_data.groupby(['Insured_class'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'EAD': sum, 'RWA_new': sum}) #20250403 George added\n",
    "\n",
    "# Add a total row to Sumry\n",
    "\n",
    "Sumry = Sumry.append(Sumry.sum(numeric_only=True), ignore_index=True) #20250403 George added\n",
    "Sumry.at[Sumry.index[-1], 'Insured_class'] = 'Total' #20250403 George added\n",
    "\n",
    "# Add a column RWA_Ratio as the ratio of RWA_new and EAD\n",
    "\n",
    "Sumry['RWA_Ratio'] = Sumry['RWA_new'] / Sumry['EAD'] #20250403 George added\n",
    "\n",
    "# print the summary\n",
    "\n",
    "print(Sumry) #20250403 George added\n",
    "\n",
    "# print columns in alphabetical ored\n",
    "\n",
    "print(sorted(res_data.columns)) #20250403 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69c70334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Group by Corporate_Applicant_Ind*****************\n",
      "   Corporate_Applicant_Ind  Loan_Number           EAD       RWA_new\n",
      "0                      0.0        54203  2.227180e+10  3.813310e+09\n",
      "1                      1.0         1426  1.384430e+06  1.045012e+05\n"
     ]
    }
   ],
   "source": [
    "# Group by Corporate_Applicant_Ind, count number of Loan_Number, sum of EAD and RWA_new\n",
    "\n",
    "print('***************Group by Corporate_Applicant_Ind*****************') \n",
    "\n",
    "print(res_data.groupby(['Corporate_Applicant_Ind'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'EAD': sum, 'RWA_new': sum})) #20250403 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c474904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For res_data, filter missing Insured_class loans\n",
    "\n",
    "res_data_Insured_class_null = res_data.loc[res_data['Insured_class'].isnull()] \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Commercial_IFRS9_PD_2024Dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
