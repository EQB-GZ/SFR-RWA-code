{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2754a081",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f46fdf8-effa-48f5-99f0-ee81fb3836a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import SFR_PD_Recalibration_2023_Lib as tool\n",
    "# import Concentra_SFR_Fit_for_Use_2024_Lib as lib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import Lib_RWA as Lib_RWA\n",
    "\n",
    "# delete lib_RWA from system modules \n",
    "\n",
    "del(sys.modules['Lib_RWA'])\n",
    "\n",
    "# delete SFR_PD_Recalibration_2023_Lib from system modules\n",
    "\n",
    "del(sys.modules['SFR_PD_Recalibration_2023_Lib'])\n",
    "\n",
    "\n",
    "import SFR_PD_Recalibration_2023_Lib as tool\n",
    "\n",
    "import Lib_RWA as Lib_RWA\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21bf9d4f-975b-42ad-b7c5-c42d70b7b5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900054f9",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dae55b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Snaphsot and RWA file information\n",
    "\n",
    "# snapshot_num = 202212 # 20250403 Fran commented out as George in S1\n",
    "# snapshot = str(snapshot_num) # 20250403 Fran commented out as George in S1\n",
    "# snapshot_date = '2022-12-31' # 20250403 Fran commented out as George in S1\n",
    "# RWA_File_from_Chenxi = 'SFR_RWA_202212.csv' #20250403 Fran added as George S1!!! Note to be consistent with the snapshot date\n",
    "\n",
    "snapshot_num = 202412 # 20250403 Fran added as George in S1 \n",
    "snapshot = str(snapshot_num) # 20250403 Fran added as George in S1\n",
    "snapshot_date = '2024-12-31' # 20250403 Fran added as George in S1\n",
    "RWA_File_from_Chenxi = 'SFR_202412_v2 (from Chenxi 20250403).csv' #20250403 Fran added as George S1!!! Note to be consistent with the snapshot date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "669d81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAR 2023 Ch5 prescribed parameters\n",
    "\n",
    "correlation_residential_mortgages = 0.15\n",
    "correlation_residential_mortgages_rental = 0.22\n",
    "\n",
    "CMHC_pd = 0.0001\n",
    "CMHC_lgd = 0.11 #according to the newly developed Sovereign LGD model\n",
    "\n",
    "lgd_gen_floor = 0.1 #general floor by CAR 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53436fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Server and Tables\n",
    "\n",
    "Server_Finance = 'EQDWP01'  \n",
    "Database_Production = 'ET_Finance_Production' \n",
    "Server_Consolidated  =  'EQSQLT01\\RISK'\n",
    "Database_Consolidated = 'Risk_Analytics'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ed6e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to Keep\n",
    "\n",
    "RWA_Info_Cols_to_Keep = ['Loan_Number','Insured_class','EAD','Advance_Amount','Years_to_maturity', 'corr_uninsured', 'RWA_standardized']\n",
    "\n",
    "PD_Cols_to_Keep = ['Loan_Number','SL_Date','PD_Pre_MOC','PD_Post_MOC_Pre_Adj','PD_Post_MOC','MRS_Bin_PD','Insured_Ind','Alt_Prime_Indicator','RemainingPrincipal_Tot_Exp','RemainingPrincipal_Excl_Partner', 'Corporate_Applicant_Ind','Combo_Province_Metro_Override_WOE', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE','Beacon_Avg_App_CoApp','Beacon_Avg_App_CoApp_WOE','BF_LTV_Tot_Exp_FSA_Dw_WF','Combo_LTV_Insured_Ind_WOE']\n",
    "\n",
    "PD_Cols_for_Corp = ['AdvancedAmount_EQB_Exp','AdvancedAmount_Total_Exp','AdvancedAmt_Incl_Part','AdvancedAmt_Excl_Part','Remaining_Term'] \n",
    "\n",
    "\n",
    "LGD_Cols_to_Keep = ['Loan_Number','MRS_Bin_LGD','Model_LGD','Mapped_LGD','Appraisal_Bin_WOE', 'Occupancy_WOE', 'Province_Foreclosure_WOE','LTV_Bin_WOE', 'Segment_Avg_LGD','Base_Line_LGD','LGD_DT_Adjusted']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58667db5",
   "metadata": {},
   "source": [
    "# Set Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc94526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "\n",
    "current_dir = os.getcwd()  # 20250403 George added\n",
    "\n",
    "# code_dir= \"C:\\\\Users\" +'\\\\' + username + '\\\\' + \"Equitable Bank\\\\EQB-Concentra Fit for Use - Fit_for_Use Development - Fit_for_Use Development\\\\RWA\\\\code\" # 20250403 George commented out Francesca/Joseph's code\n",
    "\n",
    "code_dir = current_dir # 20250403 George added\n",
    "\n",
    "\n",
    "if int(snapshot_num) == 202412:\n",
    "    input_dir = code_dir + '\\\\..\\\\' + \"Inputs\" # 20250406 George added\n",
    "    Output_dir = code_dir + '\\\\..\\\\' + \"Outputs\" #20250406 George added\n",
    "\n",
    "if int(snapshot_num) == 202212:\n",
    "    input_dir = code_dir + '\\\\..\\\\' + \"Dec. 2022 RWA Inputs\" #20250410 George added\n",
    "    Output_dir = code_dir + '\\\\..\\\\' + \"Replicated Dec 2022 Outputs\" #20250410 George added\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2dc1fd",
   "metadata": {},
   "source": [
    "# Run ID for Production Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8262947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sql_max_FeedID( snapshot ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_RE_log' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT max([FeedID]) as max_FeedID\n",
    "       FROM {table}\n",
    "       where Reporting_date =  {snapshot} \n",
    "             \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "Max_Feed_ID= tool.download_from_sql( Server_Finance, Database_Production, sql_max_FeedID( \"'\" + snapshot_date + \"'\" ) )['max_FeedID'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043d70e",
   "metadata": {},
   "source": [
    "# Load RWA Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be05664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in the RWA data from Chenxi\n",
    "\n",
    "# Import data with Loan_Number,Insured_class,CalibratedPD,Final_LGD,EAD,Advance_Amount,Years_to_maturity and corr_uninsured\n",
    "##################### load snapshot data Chenxi provided and rename#################################\n",
    "#rwa_data = pd.read_csv(input_dir +'\\\\'+'SFR_RWA_' + snapshot + '.csv', low_memory=False) #20250403 Fran commented as George in S1\n",
    "rwa_data = pd.read_csv(input_dir +'\\\\'+ RWA_File_from_Chenxi, low_memory=False) #20250403 Fran added as George in S1\n",
    "\n",
    "rwa_raw_data_0 = rwa_data[RWA_Info_Cols_to_Keep]  # 20250410 George add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234a3eed-406c-40d3-9494-5559c65cf8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53402, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4ce0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Floor the EAD on 0          \n",
    "\n",
    "rwa_raw_data_0.loc[rwa_raw_data_0['EAD']<0, ['EAD']] =0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186db2de",
   "metadata": {},
   "source": [
    "# Load Consolidated RESL Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45664bc",
   "metadata": {},
   "source": [
    "## Extract from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52af9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# retrieve risk rating attributes from Production\n",
    "\n",
    "def sql_consolidated_RESL(snapshot_date):\n",
    "    \n",
    "    table = '[Risk_Analytics].[dbo].Risk_Consolidated_RESL' \n",
    "\n",
    "    sql = f'''\n",
    "    Select\n",
    "        [Year]\n",
    "      ,[Time]\n",
    "      ,[SL_Date]\n",
    "      ,[Company]\n",
    "      ,[Loan_Number]\n",
    "      ,[CIF_number]\n",
    "      ,[Business_Line]\n",
    "      ,[Loan_Status]\n",
    "      ,[Loan_Type]\n",
    "      ,[Property_Code]\n",
    "      ,[Address]\n",
    "      ,[City]\n",
    "      ,[Province]\n",
    "      ,[Postal_Code]\n",
    "      ,[Metro]\n",
    "      ,[Tier]\n",
    "      ,[Securitized_Indicator]\n",
    "      ,[Alt_Prime_Ind]\n",
    "      ,[Insured_Ind]\n",
    "      ,[Insurer_Name]\n",
    "      ,[Standard_Risk_Rating]\n",
    "      ,[EQB_Authorized_Loan_Amount]\n",
    "      ,[Remaining_Principal]\n",
    "      ,[Original_Principal_Amount]\n",
    "      ,[HELOC_Balance]\n",
    "      ,[Accrued_Interest]\n",
    "      ,[Sundry_Account]\n",
    "      ,[Fair_Value]\n",
    "      ,[Exposure_at_Default]\n",
    "      ,[Borrower_Name]\n",
    "      ,[Date_Of_Birth]\n",
    "      ,[Borrower_Age]\n",
    "      ,[Servicer_ID]\n",
    "      ,[Servicer_Name]\n",
    "      ,[Servicer_Name_Full]\n",
    "      ,[Maturity_Date]\n",
    "      ,[Renewal_Date]\n",
    "      ,[Advance_Date]\n",
    "      ,[Funded_Date]\n",
    "      ,[Appraisal_Value_Inception]\n",
    "      ,[Appraisal_Value_Current]\n",
    "      ,[LTV_Inception]\n",
    "      ,[LTV_Current]\n",
    "      ,[Remaining_Term]\n",
    "      ,[Term]\n",
    "      ,[Interest_Rate_Raw]\n",
    "      ,[Interest_Rate_New]\n",
    "      ,[Rate_Type]\n",
    "      ,[Payment_Plan]\n",
    "      ,[Payment_Plan_Description]\n",
    "      ,[Default_Indicator]\n",
    "      ,[Arrears_Days]\n",
    "      ,[Arrears_Status]\n",
    "      ,[Arrears_Days_Group]\n",
    "      ,[Gemstone]\n",
    "      ,[Inception_Beacon_Score]\n",
    "      ,[Current_Beacon_Score]\n",
    "      ,[Current_BNI_Score]\n",
    "      ,[Amortization_Inception]\n",
    "      ,[Amort_Rem]\n",
    "      ,[Branch]\n",
    "      ,[Occupancy]\n",
    "      ,[Funding_GDS]\n",
    "      ,[Funding_TDS]\n",
    "      ,[Conforming_Ind_SFRAlt]\n",
    "      ,[Conforming_Reason]\n",
    "      ,[Dwelling_Type]\n",
    "      ,[Salary_BFS_Indicator]\n",
    "      ,[Total_Household_Income]\n",
    "      ,[Loan_Purpose]\n",
    "      ,[Third_Party_Name]\n",
    "      ,[High_Rise_Condo_Indicator]\n",
    "      ,[AIRB_Retail_Model_PD_Value]\n",
    "      ,[AIRB_Retail_Calibrated_PD_Value]\n",
    "      ,[AIRB_Retail_PD_Pool]\n",
    "      ,[AIRB_Retail_Model_LGD_Value]\n",
    "      ,[AIRB_Retail_Calibrated_LGD_Value]\n",
    "      ,[AIRB_Retail_Downturn_LGD_Value]\n",
    "      ,[AIRB_Retail_Final_LGD_Value]\n",
    "      ,[AIRB_Retail_LGD_Pool]\n",
    "      ,[LOC_Credit_Limit]\n",
    "      ,[Youngest_Date_Of_Birth]\n",
    "      ,[Youngest_Age]\n",
    "      ,[Last_Update_Date]\n",
    "      ,[Last_Update_By]\n",
    "      from [Risk_Analytics].[dbo].[Risk_Consolidated_RESL]\n",
    "      where SL_Date = '{snapshot_date}' and Company = 'EQB'\n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "\n",
    "Consolidated_RESL_Data_Raw = tool.download_from_sql(Server_Consolidated, Database_Consolidated, sql_consolidated_RESL(snapshot_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d16a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EQB               51174\n",
       "First National     7162\n",
       "Paradigm           3034\n",
       "Name: Third_Party_Name, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count values of Third_Party_Name\n",
    "\n",
    "Consolidated_RESL_Data_Raw['Third_Party_Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b1819",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5637b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Loan_Number to integer\n",
    "\n",
    "Consolidated_RESL_Data_Raw['Loan_Number'] = Consolidated_RESL_Data_Raw['Loan_Number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b485a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_8452\\160977798.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Consolidated_RESL_Data.rename(columns={'Alt_Prime_Ind':'Alt_Prime_Indicator', 'Third_Party_Name':'Sub_Product'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Keep columns Loan_Number, SL_Date, Alt_Prime_Ind, Insured_Ind, Default_Indicator, Third_Party_Name\n",
    "\n",
    "Consolidated_RESL_Data = Consolidated_RESL_Data_Raw[['Loan_Number','Alt_Prime_Ind','Default_Indicator','Third_Party_Name', 'SL_Date']]\n",
    "\n",
    "# Rename columns: Alt_Prime_Ind to Alt_Prime_Indicator, Third_Party_Name to Sub_Product \n",
    "\n",
    "Consolidated_RESL_Data.rename(columns={'Alt_Prime_Ind':'Alt_Prime_Indicator', 'Third_Party_Name':'Sub_Product'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab318d",
   "metadata": {},
   "source": [
    "# Load Risk Rating Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f43ec5",
   "metadata": {},
   "source": [
    "## Extract Risk Rating Attributes from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a262ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# retrieve risk rating attributes from Production\n",
    "\n",
    "def sql_risk_rating_attributes(Year,Time):\n",
    "    \n",
    "    table = '[ET_Finance_Production].[dbo].t_SFR_Risk_Rating_Attributes' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot_date) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "       [Year]\n",
    "      ,[Time]\n",
    "      ,[Loan_Number]\n",
    "      ,[X1_Average_Beacon_Score_PD]\n",
    "      ,[X2_Current_LTV_PD]\n",
    "      ,[X2_Loan_Class_PD]\n",
    "      ,[X3_Worst_Delinquency_Two_Years_Max_PD]\n",
    "      ,[X4_Province_PD]\n",
    "      ,[X1_FSA_LGD]\n",
    "      ,[X1_Province_LGD]\n",
    "      ,[X2_LTV_LGD]\n",
    "      ,[X3_Appraisal_LGD]\n",
    "      ,[X4_Occupancy_LGD]\n",
    "      ,[Current_Delinquency_Days]\n",
    "      ,[Unlikely_to_Pay]\n",
    "      ,[Remaining_Principal_EQB]\n",
    "      ,[Remaining_Principal_with_Partner]\n",
    "      ,[Remaining_Principal_with_Partner_HELOC]\n",
    "      ,[DEF_Current_Balance_HELOC]\n",
    "      ,[Partner_Percentage]\n",
    "      ,[Funding_Appraisal_Value]\n",
    "      ,[Purchase_Price]\n",
    "      ,[Property_Value]\n",
    "      ,[Tenure]\n",
    "      ,[Risk_Rating_Tier]\n",
    "      ,[FSA]\n",
    "      ,[City]\n",
    "      ,[Metro]\n",
    "      ,[Province]\n",
    "      ,[Dwelling_Type]\n",
    "      ,[Fair_Values]\n",
    "      ,[Accrued_Interest]\n",
    "      ,[Advance_Date]\n",
    "      ,[Renewal_Date]\n",
    "      ,[old_Loan_Number_Secondary_Suites]\n",
    "      ,[HPI_Funding_FSA_Dwelling]\n",
    "      ,[HPI_Funding_FSA_Dwelling_Style]\n",
    "      ,[HPI_Funding_FSA_Aggregate]\n",
    "      ,[HPI_Reporting_FSA_Dwelling]\n",
    "      ,[HPI_Reporting_FSA_Dwelling_Style]\n",
    "      ,[HPI_Reporting_FSA_Aggregate]\n",
    "      ,[HPI_Funding_City_Dwelling]\n",
    "      ,[HPI_Funding_City_Dwelling_Style]\n",
    "      ,[HPI_Funding_City_Aggregate]\n",
    "      ,[HPI_Reporting_City_Dwelling]\n",
    "      ,[HPI_Reporting_City_Dwelling_Style]\n",
    "      ,[HPI_Reporting_City_Aggregate]\n",
    "      ,[HPI_Funding_Metro_Dwelling]\n",
    "      ,[HPI_Funding_Metro_Dwelling_Style]\n",
    "      ,[HPI_Funding_Metro_Aggregate]\n",
    "      ,[HPI_Reporting_Metro_Dwelling]\n",
    "      ,[HPI_Reporting_Metro_Dwelling_Style]\n",
    "      ,[HPI_Reporting_Metro_Aggregate]\n",
    "      ,[HPI_Funding_Province_Dwelling]\n",
    "      ,[HPI_Funding_Province_Dwelling_Style]\n",
    "      ,[HPI_Funding_Province_Aggregate]\n",
    "      ,[HPI_Reporting_Province_Dwelling]\n",
    "      ,[HPI_Reporting_Province_Dwelling_Style]\n",
    "      ,[HPI_Reporting_Province_Aggregate]\n",
    "      ,[HPI_Funding_National_Dwelling]\n",
    "      ,[HPI_Funding_National_Dwelling_Style]\n",
    "      ,[HPI_Funding_National_Aggregate]\n",
    "      ,[HPI_Reporting_National_Dwelling]\n",
    "      ,[HPI_Reporting_National_Dwelling_Style]\n",
    "      ,[HPI_Reporting_National_Aggregate]\n",
    "      ,[DLGD_BF_LTV]\n",
    "      ,[EAD]\n",
    "      ,[Remaining_Principal_Post_CRM]\n",
    "      ,[Principal_Amount_Post_CRM]\n",
    "      ,[Loan_Class_Post_CRM]\n",
    "      ,[Price_Correction]\n",
    "      ,[Teranet_Region]\n",
    "      ,[Teranet_Funding_HPI]\n",
    "      ,[Teranet_Reporting_HPI]       FROM {table}\n",
    "       where Year =  '{Year}' and Time = '{Time}'\n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "\n",
    "Risk_Rating_Attribute_Prod_Data_Raw = tool.download_from_sql( Server_Finance, Database_Production, sql_risk_rating_attributes(Year='Y'+ str(pd.to_datetime(snapshot_date).year), Time=pd.to_datetime(snapshot_date).strftime('%b') ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acb7df",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9fa3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Accrued_Interest', 'Advance_Date', 'City', 'Current_Delinquency_Days', 'DEF_Current_Balance_HELOC', 'DLGD_BF_LTV', 'Dwelling_Type', 'EAD', 'FSA', 'Fair_Values', 'Funding_Appraisal_Value', 'HPI_Funding_City_Aggregate', 'HPI_Funding_City_Dwelling', 'HPI_Funding_City_Dwelling_Style', 'HPI_Funding_FSA_Aggregate', 'HPI_Funding_FSA_Dwelling', 'HPI_Funding_FSA_Dwelling_Style', 'HPI_Funding_Metro_Aggregate', 'HPI_Funding_Metro_Dwelling', 'HPI_Funding_Metro_Dwelling_Style', 'HPI_Funding_National_Aggregate', 'HPI_Funding_National_Dwelling', 'HPI_Funding_National_Dwelling_Style', 'HPI_Funding_Province_Aggregate', 'HPI_Funding_Province_Dwelling', 'HPI_Funding_Province_Dwelling_Style', 'HPI_Reporting_City_Aggregate', 'HPI_Reporting_City_Dwelling', 'HPI_Reporting_City_Dwelling_Style', 'HPI_Reporting_FSA_Aggregate', 'HPI_Reporting_FSA_Dwelling', 'HPI_Reporting_FSA_Dwelling_Style', 'HPI_Reporting_Metro_Aggregate', 'HPI_Reporting_Metro_Dwelling', 'HPI_Reporting_Metro_Dwelling_Style',\n",
      "       'HPI_Reporting_National_Aggregate', 'HPI_Reporting_National_Dwelling', 'HPI_Reporting_National_Dwelling_Style', 'HPI_Reporting_Province_Aggregate', 'HPI_Reporting_Province_Dwelling', 'HPI_Reporting_Province_Dwelling_Style', 'Loan_Class_Post_CRM', 'Loan_Number', 'Metro', 'Partner_Percentage', 'Price_Correction', 'Principal_Amount_Post_CRM', 'Property_Value', 'Province', 'Purchase_Price', 'Remaining_Principal_EQB', 'Remaining_Principal_Post_CRM', 'Remaining_Principal_with_Partner', 'Remaining_Principal_with_Partner_HELOC', 'Renewal_Date', 'Risk_Rating_Tier', 'Tenure', 'Teranet_Funding_HPI', 'Teranet_Region', 'Teranet_Reporting_HPI', 'Time', 'Unlikely_to_Pay', 'X1_Average_Beacon_Score_PD', 'X1_FSA_LGD', 'X1_Province_LGD', 'X2_Current_LTV_PD', 'X2_LTV_LGD', 'X2_Loan_Class_PD', 'X3_Appraisal_LGD', 'X3_Worst_Delinquency_Two_Years_Max_PD', 'X4_Occupancy_LGD', 'X4_Province_PD', 'Year', 'old_Loan_Number_Secondary_Suites'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    " # Print columns in alphabetical order\n",
    "\n",
    "print(Risk_Rating_Attribute_Prod_Data_Raw.columns.sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0468124",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e41f6c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_8452\\1469802393.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Risk_Rating_Attribute_Prod_Data.rename(columns={'Remaining_Principal_EQB':'RemainingPrincipal_Excl_Partner', 'Remaining_Principal_with_Partner_HELOC':'RemainingPrincipal_Tot_Exp', 'X1_Average_Beacon_Score_PD':'Beacon_Avg_App_CoApp', 'X2_Current_LTV_PD':'BF_LTV_Tot_Exp_FSA_Dw_WF', 'X2_Loan_Class_PD':'Insured_Ind', 'X3_Worst_Delinquency_Two_Years_Max_PD':'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'X2_LTV_LGD':'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'X3_Appraisal_LGD':'BF_Appr_Prov_Dw', 'X4_Occupancy_LGD':'Occupancy'}, inplace=True)\n",
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_8452\\1469802393.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Risk_Rating_Attribute_Prod_Data['Insured_Ind'] = Risk_Rating_Attribute_Prod_Data['Insured_Ind'].replace({'Uninsured':'Not Insured'})\n"
     ]
    }
   ],
   "source": [
    "# Keep Columns Loan_Number, Remaining_Principal_EQB, Remaining_Principal_with_Partner, Remaining_Principal_with_Partner_HELOC, Remaining_Principal_Post_CRM, 'X1_Average_Beacon_Score_PD', 'X2_Current_LTV_PD', 'X2_Loan_Class_PD', 'X3_Worst_Delinquency_Two_Years_Max_PD', 'X4_Province_PD', 'X1_FSA_LGD', 'X1_Province_LGD', 'X2_LTV_LGD', 'X3_Appraisal_LGD', 'X4_Occupancy_LGD', 'Current_Delinquency_Days'\n",
    "\n",
    "Risk_Rating_Attribute_Prod_Data = Risk_Rating_Attribute_Prod_Data_Raw[['Loan_Number','Remaining_Principal_EQB','Remaining_Principal_with_Partner_HELOC','X1_Average_Beacon_Score_PD','X2_Current_LTV_PD','X2_Loan_Class_PD','X3_Worst_Delinquency_Two_Years_Max_PD','X2_LTV_LGD','X3_Appraisal_LGD','X4_Occupancy_LGD','Current_Delinquency_Days']] \n",
    "\n",
    "# Renaming columns: Remaining_Principal_EQB to RemainingPrincipal_Excl_Partner, Remainining_Principal_with_Partner_HELOC to RemainingPrincipal_Tot_Exp, X1_Average_Beacon_Score_PD to Beacon_Avg_App_CoApp, X2_Current_LTV_PD to BF_LTV_Tot_Exp_FSA_Dw_WF, X2_Loan_Class_PD to Insured_Ind, X3_Worst_Delinquency_Two_Years_Max_PD to Prior_24_Worse_Delinquent_Status_FMT_Adj, X2_LTV_LGD to BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw, X3_Appraisal_LGD to BF_Appr_Prov_Dw, X4_Occupancy_LGD\n",
    "\n",
    "Risk_Rating_Attribute_Prod_Data.rename(columns={'Remaining_Principal_EQB':'RemainingPrincipal_Excl_Partner', 'Remaining_Principal_with_Partner_HELOC':'RemainingPrincipal_Tot_Exp', 'X1_Average_Beacon_Score_PD':'Beacon_Avg_App_CoApp', 'X2_Current_LTV_PD':'BF_LTV_Tot_Exp_FSA_Dw_WF', 'X2_Loan_Class_PD':'Insured_Ind', 'X3_Worst_Delinquency_Two_Years_Max_PD':'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'X2_LTV_LGD':'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'X3_Appraisal_LGD':'BF_Appr_Prov_Dw', 'X4_Occupancy_LGD':'Occupancy'}, inplace=True) \n",
    "\n",
    "# Change the values of Insured_Ind: Uninsured to 'Not Insured'\n",
    "\n",
    "Risk_Rating_Attribute_Prod_Data['Insured_Ind'] = Risk_Rating_Attribute_Prod_Data['Insured_Ind'].replace({'Uninsured':'Not Insured'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96fc7a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_8452\\937766065.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Risk_Rating_Attribute_Prod_Data['Loan_Number'] = Risk_Rating_Attribute_Prod_Data['Loan_Number'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Change Loan_Number to integer\n",
    "\n",
    "Risk_Rating_Attribute_Prod_Data['Loan_Number'] = Risk_Rating_Attribute_Prod_Data['Loan_Number'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fe2c6",
   "metadata": {},
   "source": [
    "# Load PD Driver Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf78ce5",
   "metadata": {},
   "source": [
    "## Extract from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "944d357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# retrieve PD WOE data from Production\n",
    "\n",
    "def sql_PD_Driver(snapshot_date):\n",
    "    \n",
    "    table = '[Risk_Modelling_Dataset].[dbo].[vw_SFR_PD_Model_Driver_Dataset_Including_Post_Def]'\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "      [Loan_Number],\n",
    "      Sub_Product,\n",
    "      Default_Ind,\n",
    "      Post_Default_Ind\n",
    "       FROM {table}\n",
    "       where SL_Date =  '{snapshot_date}'\n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "PD_Driver_Data_Raw = tool.download_from_sql(server = Server_Consolidated, database = 'Risk_Modelling_Dataset', sql = sql_PD_Driver(snapshot_date) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688813d",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "409cebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Loan_Number to integer\n",
    "\n",
    "PD_Driver_Data_Raw['Loan_Number'] = PD_Driver_Data_Raw['Loan_Number'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40eb94",
   "metadata": {},
   "source": [
    "# Load PD WOE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ab2b5",
   "metadata": {},
   "source": [
    "## Extract PD WOE from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cc18974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# retrieve PD WOE data from Production\n",
    "\n",
    "def sql_PD_WOE( Max_Feed_ID ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_X_WoE_PD_Result' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot_date) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "      [LoanNumber]\n",
    "      ,[X1_Average_Beacon_WoE]\n",
    "      ,[X2_Current_LTV_WoE]\n",
    "      ,[X3_Worst_Delinquency_Status_WoE]\n",
    "      ,[X4_Province_WoE]\n",
    "      ,[LogOdds]\n",
    "      ,[CalibratedPD]\n",
    "      ,[PDResult]\n",
    "      ,[RiskRating]\n",
    "      ,[RiskRatingCategory]\n",
    "       FROM {table}\n",
    "       where RunID =  {Max_Feed_ID} \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "PD_WOE_Prod_Data_Raw = tool.download_from_sql( Server_Finance, Database_Production, sql_PD_WOE(Max_Feed_ID) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c839dbd",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6ab93bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of PD_WOE_Prod_Data_Raw:\n",
      "(53402, 10)\n",
      "Count of loans by RiskRating:\n",
      "Min and max of CalibratedPD by RiskRating:\n",
      "Count of values of X2_Current_LTV_WoE:\n",
      "Count of values of X4_Province_WoE:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0.165650    26175\n",
       "-0.389936    13575\n",
       "-0.161658     7464\n",
       " 0.253031     5448\n",
       " 0.000000      740\n",
       "Name: X4_Province_WoE, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of PD_WOE_Prod_Data_Raw\n",
    "\n",
    "print('Shape of PD_WOE_Prod_Data_Raw:')\n",
    "print(PD_WOE_Prod_Data_Raw.shape)\n",
    "\n",
    "\n",
    "# Group by RiskRating, count the number of loans\n",
    "print('Count of loans by RiskRating:')\n",
    "PD_WOE_Prod_Data_Raw['RiskRating'].value_counts()\n",
    "# Group by RiskRating, get min and max of CalibratedPD\n",
    "\n",
    "print('Min and max of CalibratedPD by RiskRating:')\n",
    "\n",
    "PD_WOE_Prod_Data_Raw.groupby(['RiskRating']).agg({'CalibratedPD': ['min', 'max']}).reset_index().sort_values(by=['RiskRating'])\n",
    "\n",
    "# Count values of X2_Current_LTV_WoE\n",
    "\n",
    "print('Count of values of X2_Current_LTV_WoE:')\n",
    "\n",
    "PD_WOE_Prod_Data_Raw['X2_Current_LTV_WoE'].value_counts()\n",
    "\n",
    "# Count value of X4_Province_WoE\n",
    "\n",
    "print('Count of values of X4_Province_WoE:')\n",
    "\n",
    "PD_WOE_Prod_Data_Raw['X4_Province_WoE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295dfd72",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68c262e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in PD_WOE_Prod_Data_Raw: CalibratedPD to PD_Post_MOC, RiskRating to MRS_Bin_PD, X1_Average_Beacon_WoE to Beacon_Avg_App_CoApp_WOE, X2_Current_LTV_WoE to Combo_LTV_Insured_Ind_WOE, X3_Worst_Delinquency_Status_WoE to Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE, X4_Province_WoE to Combo_Province_Metro_Override_WOE, LoanNumber to Loan_Number\n",
    "\n",
    "PD_WOE_Prod_Data = PD_WOE_Prod_Data_Raw.rename(columns={'CalibratedPD': 'PD_Post_MOC', 'RiskRating': 'MRS_Bin_PD', 'X1_Average_Beacon_WoE': 'Beacon_Avg_App_CoApp_WOE', 'X2_Current_LTV_WoE': 'Combo_LTV_Insured_Ind_WOE', 'X3_Worst_Delinquency_Status_WoE': 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE', 'X4_Province_WoE': 'Combo_Province_Metro_Override_WOE', 'LoanNumber': 'Loan_Number'})\n",
    "\n",
    "# Change Loan_Number to integer\n",
    "\n",
    "PD_WOE_Prod_Data['Loan_Number'] = PD_WOE_Prod_Data['Loan_Number'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f106a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Columns Loan_Number, PD_Post_MOC, MRS_Bin_PD, Beacon_Avg_App_CoApp_WOE, Combo_LTV_Insured_Ind_WOE, Combo_Province_Metro_Override_WOE, Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE\n",
    "\n",
    "PD_WOE_Prod_Data = PD_WOE_Prod_Data[['Loan_Number','PD_Post_MOC','MRS_Bin_PD','Beacon_Avg_App_CoApp_WOE','Combo_LTV_Insured_Ind_WOE','Combo_Province_Metro_Override_WOE','Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0fde4",
   "metadata": {},
   "source": [
    "# Load PD Scoring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78daf3b",
   "metadata": {},
   "source": [
    "## Extract Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87e73271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new SFR PD model generated PD \n",
    "\n",
    "#new_pd_data = pd.read_csv( Active_dir +'\\\\'+'PARAM_Pred_PD'  + '.csv', low_memory=False) # 20250402 George Commented out \n",
    "PD_Data_Scored = pd.read_pickle(input_dir + '\\\\Rating_July2020_to_Dec2024_EQB (from George 20250414).pkl') # 20250402 George added\n",
    "\n",
    "PD_Data_Scored_red = PD_Data_Scored.loc[PD_Data_Scored['SL_Date'] == snapshot_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac44157",
   "metadata": {},
   "source": [
    "## Compare with PD Driver Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bb79e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of loans by Merge_PDScoring_PDDriver:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Both               55629\n",
       "PD Scoring Only        0\n",
       "PD Driver Only         0\n",
       "Name: Merge_PDScoring_PDDriver, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge PD_Data_Scored_red with PD_Driver_Data_Raw on Loan_Number\n",
    "\n",
    "PD_Scoring_Driver_Merge = pd.merge(PD_Data_Scored_red, PD_Driver_Data_Raw[['Loan_Number']], on='Loan_Number', how='outer', indicator= 'Merge_PDScoring_PDDriver')\n",
    "\n",
    "# Change values of  Merge_PDScoring_PDDriver to be more descriptive\n",
    "\n",
    "PD_Scoring_Driver_Merge['Merge_PDScoring_PDDriver'] = PD_Scoring_Driver_Merge['Merge_PDScoring_PDDriver'].replace({'both': 'Both', 'left_only': 'PD Scoring Only', 'right_only': 'PD Driver Only'})\n",
    "\n",
    "# Group by Merge_PDScoring_PDDriver, count the number of loans\n",
    "\n",
    "print('Count of loans by Merge_PDScoring_PDDriver:')\n",
    "\n",
    "PD_Scoring_Driver_Merge['Merge_PDScoring_PDDriver'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9969430",
   "metadata": {},
   "source": [
    "## Compare with PD WOE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35e85987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of loans by Merge_PDScoring_PDWOE, Corporate_Applicant_Ind, and Sub_Product:\n",
      "   Merge_PDScoring_PDWOE  Corporate_Applicant_Ind     Sub_Product  Count\n",
      "0        PD Scoring Only                      0.0             EQB    828\n",
      "1        PD Scoring Only                      0.0  First National      0\n",
      "2        PD Scoring Only                      0.0            GMAC      6\n",
      "3        PD Scoring Only                      0.0        Paradigm      0\n",
      "4        PD Scoring Only                      1.0             EQB   1423\n",
      "5        PD Scoring Only                      1.0  First National      0\n",
      "6        PD Scoring Only                      1.0            GMAC      0\n",
      "7        PD Scoring Only                      1.0        Paradigm      0\n",
      "8            PD WOE Only                      0.0             EQB      0\n",
      "9            PD WOE Only                      0.0  First National      0\n",
      "10           PD WOE Only                      0.0            GMAC      0\n",
      "11           PD WOE Only                      0.0        Paradigm      0\n",
      "12           PD WOE Only                      1.0             EQB      0\n",
      "13           PD WOE Only                      1.0  First National      0\n",
      "14           PD WOE Only                      1.0            GMAC      0\n",
      "15           PD WOE Only                      1.0        Paradigm      0\n",
      "16                  Both                      0.0             EQB  43152\n",
      "17                  Both                      0.0  First National   7162\n",
      "18                  Both                      0.0            GMAC     22\n",
      "19                  Both                      0.0        Paradigm   3033\n",
      "20                  Both                      1.0             EQB      3\n",
      "21                  Both                      1.0  First National      0\n",
      "22                  Both                      1.0            GMAC      0\n",
      "23                  Both                      1.0        Paradigm      0\n"
     ]
    }
   ],
   "source": [
    "# Merge PD_Data_Scored_red with PD_WOE_Prod_Data on Loan_Number\n",
    "\n",
    "PD_Scoring_WOE_Merge = pd.merge(PD_Data_Scored_red, PD_WOE_Prod_Data[['Loan_Number']], on='Loan_Number', how='outer', indicator= 'Merge_PDScoring_PDWOE')\n",
    "\n",
    "# Change values of  Merge_PDScoring_PDWOE to be more descriptive\n",
    "\n",
    "PD_Scoring_WOE_Merge['Merge_PDScoring_PDWOE'] = PD_Scoring_WOE_Merge['Merge_PDScoring_PDWOE'].replace({'both': 'Both', 'left_only': 'PD Scoring Only', 'right_only': 'PD WOE Only'})\n",
    "\n",
    "# Group by Merge_PDScoring_PDWOE and Corporate_Applicant_Ind, count the number of loans\n",
    "\n",
    "print('Count of loans by Merge_PDScoring_PDWOE, Corporate_Applicant_Ind, and Sub_Product:')\n",
    "\n",
    "print(PD_Scoring_WOE_Merge.groupby(['Merge_PDScoring_PDWOE', 'Corporate_Applicant_Ind','Sub_Product']).size().reset_index(name='Count').sort_values(by=['Merge_PDScoring_PDWOE', 'Corporate_Applicant_Ind']))\n",
    "\n",
    "# Filter PD_Scoring_WOE_Merge to only include loans that are not in both PD_Data_Scored_red and PD_WOE_Prod_Data\n",
    "\n",
    "PD_Scoring_WOE_Merge_not_in_both = PD_Scoring_WOE_Merge[PD_Scoring_WOE_Merge['Merge_PDScoring_PDWOE'] != 'Both']\n",
    "\n",
    "# save PD_Scoring_WOE_Merge_not_in_both to csv\n",
    "\n",
    "PD_Scoring_WOE_Merge_not_in_both[['Loan_Number','Sub_Product','Corporate_Applicant_Ind','Merge_PDScoring_PDWOE']].to_csv(Output_dir + '\\\\' + 'PD_Scoring_WOE_Merge_not_in_both.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c44a9d",
   "metadata": {},
   "source": [
    "## Compare with Consolidated RESL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b6e9dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of loans by _merge_Consolidated_PD_Scoring:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Both                      55629\n",
       "Consolidated_RESL_Only     5741\n",
       "PD_Scoring_Only               0\n",
       "Name: _merge_Consolidated_PD_Scoring, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Consolidated_RESL_Data_Raw and PD_Data_Scored_red on Loan_Number\n",
    "\n",
    "Consolidated_PD_Scoring = Consolidated_RESL_Data_Raw.merge(PD_Data_Scored_red[['Loan_Number']], how='outer', on = 'Loan_Number', suffixes=('_Consoldidated', '_Scoring'), indicator= '_merge_Consolidated_PD_Scoring') \n",
    "\n",
    "# change _merge_Consolidated_PD_Scoring to be more descriptive\n",
    "\n",
    "Consolidated_PD_Scoring['_merge_Consolidated_PD_Scoring'] = Consolidated_PD_Scoring['_merge_Consolidated_PD_Scoring'].replace({'left_only': 'Consolidated_RESL_Only', 'right_only': 'PD_Scoring_Only', 'both': 'Both'}) \n",
    "\n",
    "\n",
    "# Group by _merge_Consolidated_PD_Scoring, count the number of loans\n",
    "\n",
    "print('Count of loans by _merge_Consolidated_PD_Scoring:')\n",
    "\n",
    "Consolidated_PD_Scoring['_merge_Consolidated_PD_Scoring'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0c489",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1bfaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep  column Loan_Number, Corporate_Applicant_Ind\n",
    "\n",
    "PD_Scored_Data = PD_Data_Scored_red[['Loan_Number','Corporate_Applicant_Ind']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc65d0",
   "metadata": {},
   "source": [
    "# Load LGD Scoring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43872949",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fef0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new SFR LGD model generated LGD and apply LGD floor \n",
    "\n",
    "\n",
    "if snapshot_num == 202212:\n",
    "\n",
    "    LGD_Scoring_Data_Raw = pd.read_pickle(input_dir + '\\\\eqb_lgd_scored_2022_12 (from Abhi 20250410).pkl') # 20250406 George added\n",
    "\n",
    "if snapshot_num == 202412:\n",
    "\n",
    "    LGD_Scoring_Data_Raw = pd.read_pickle(input_dir + '\\\\eqb_lgd_scored_2024_12 (from Abhi 20250404).pkl') # 20250406 George added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb8f88",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b41be508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Appraisal_Bin', 'Appraisal_Bin_WOE', 'Appraisal_Bin_WOE', 'BF_Appr_Prov_Dw', 'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'Default_Ind', 'Final_LGD', 'Foreclosure_Ind', 'Foreclosure_Ind_WOE', 'Insured_Ind', 'LR_Avg_LGD', 'LTV_Bin', 'LTV_Bin_WOE', 'LTV_Bin_WOE', 'LoanType', 'Loan_Number', 'MRS_Bin', 'Mapped_LGD', 'Occupancy', 'Occupancy_WOE', 'Pred_LGD', 'Province_Foreclosure', 'Province_Foreclosure_WOE', 'RemainingPrincipal_Excl_Partner', 'SL_Date', 'Sub_Product']\n"
     ]
    }
   ],
   "source": [
    "# print columns in alphabetical order in the dataframe \n",
    "\n",
    "print(sorted(LGD_Scoring_Data_Raw.columns)) #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "279fd17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by MRS_Bin, calculate the min and max of Mapped_LGD and Final_LGD:\n",
      "  MRS_Bin Mapped_LGD           Final_LGD        \n",
      "                 min       max       min     max\n",
      "0       1   0.010912  0.010912    0.1074  0.1074\n",
      "1       2   0.029987  0.029987    0.1821  0.1821\n",
      "2       3   0.056927  0.056927    0.2528  0.2528\n",
      "3       4   0.101136  0.101136    0.5355  0.5355\n"
     ]
    }
   ],
   "source": [
    "# Grouped by MRS_Bin, calculate the min and max of Mapped_LGD and Final_LGD\n",
    "\n",
    "print('Grouped by MRS_Bin, calculate the min and max of Mapped_LGD and Final_LGD:')\n",
    "\n",
    "print(LGD_Scoring_Data_Raw.groupby(['MRS_Bin']).agg({'Mapped_LGD': ['min', 'max'], 'Final_LGD': ['min', 'max']}).reset_index().sort_values(by=['MRS_Bin'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9103b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8d2e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LTV_Bin_WOE', 'Appraisal_Bin_WOE']\n"
     ]
    }
   ],
   "source": [
    "# print duplicated columns \n",
    "\n",
    "print(LGD_Scoring_Data_Raw.columns[LGD_Scoring_Data_Raw.columns.duplicated()].tolist()) #20250412 George added\n",
    "\n",
    "# Remove duplicated columns \n",
    "\n",
    "LGD_Scoring_Data = LGD_Scoring_Data_Raw.loc[:,~LGD_Scoring_Data_Raw.columns.duplicated()] #20250412 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66c90f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "\n",
    "LGD_Scoring_Data = LGD_Scoring_Data.rename({'MRS_Bin':'MRS_Bin_LGD','Final_LGD':'Model_LGD'}, axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca169c92",
   "metadata": {},
   "source": [
    "# Load LGD WOE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7677c73e",
   "metadata": {},
   "source": [
    "## Extract from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4109f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# retrieve LGD WOE data from Production\n",
    "\n",
    "def sql_LGD_WOE( Max_Feed_ID ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_X_WoE_LGD_Result' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot_date) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "      [LoanNumber]\n",
    "      ,[X1_Region_WoE]\n",
    "      ,[X2_LTV_WoE]\n",
    "      ,[X3_Appraisal_WoE]\n",
    "      ,[X4_Occupancy_WoE]\n",
    "      ,[LogOdds]\n",
    "      ,[LGDResult]\n",
    "      ,[CalibratedLGD]\n",
    "      ,[RiskRating]\n",
    "      ,[RiskRatingCategory]\n",
    "      ,[SuccessOrFail]\n",
    "      ,[Comments]\n",
    "      ,[X_LGD_Overall]\n",
    "      ,[Add_on_LGD]\n",
    "      ,[Downturn_LGD]\n",
    "      ,[Final_LGD]\n",
    "       FROM {table}\n",
    "       where RunID =  {Max_Feed_ID} \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "LGD_WOE_Prod_Data_Raw = tool.download_from_sql( Server_Finance, Database_Production, sql_LGD_WOE(Max_Feed_ID) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13fba59",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da8c6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of values of CalibratedLGD:\n",
      "Count of values of RiskRating:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pool 2    20716\n",
       "Pool 1    20384\n",
       "Pool 4     6857\n",
       "Pool 3     5445\n",
       "Name: RiskRating, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count values of CalibratedLGD\n",
    "\n",
    "print('Count of values of CalibratedLGD:')\n",
    "\n",
    "LGD_WOE_Prod_Data_Raw['CalibratedLGD'].value_counts()\n",
    "\n",
    "# Count values of RiskRating\n",
    "\n",
    "print('Count of values of RiskRating:')\n",
    "\n",
    "LGD_WOE_Prod_Data_Raw['RiskRating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551591cb",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d9a4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Columns LoanNumber, Calibrated LGD, X1_Region_WoE, X2_LTV_WoE, X3_Appraisal_WoE, X4_Occupancy_WoE, RiskRating\n",
    "\n",
    "LGD_WOE_Prod_Data = LGD_WOE_Prod_Data_Raw[['LoanNumber','CalibratedLGD','X1_Region_WoE','X2_LTV_WoE','X3_Appraisal_WoE','X4_Occupancy_WoE','RiskRating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "010ecdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename Columns: LoanNumber to Loan_Number, CalibratedLGD to Model_LGD, RiskRating to MRS_Bin_LGD, X1_Region_WoE to Province_Foreclosure_WOE, X2_LTV_WoE to LTV_Bin_WOE, X3_Appraisal_WoE to Appraisal_Bin_WOE, X4_Occupancy_WoE to Occupancy_WOE\n",
    "\n",
    "LGD_WOE_Prod_Data = LGD_WOE_Prod_Data.rename(columns={'LoanNumber':'Loan_Number','CalibratedLGD':'Model_LGD','RiskRating':'MRS_Bin_LGD','X1_Region_WoE':'Province_Foreclosure_WOE','X2_LTV_WoE':'LTV_Bin_WOE','X3_Appraisal_WoE':'Appraisal_Bin_WOE','X4_Occupancy_WoE':'Occupancy_WOE'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "244df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hard code Mapped LGD values because it is not in the data set. If Model_LGD = 0.1074, then Mapped_LGD = 0.010912; if Model_LGD = 0.1821, then Mapped_LGD = 0.029987; if Model_LGD = 0.2528, then Mapped_LGD = 0.056927; if Model_LGD = 0.5355, then Mapped_LGD = 0.101136. This is based on the mapping in the Abhi's scoring LGD data in Dec. 2024.\n",
    "\n",
    "LGD_WOE_Prod_Data['Mapped_LGD'] = np.where(np.round(LGD_WOE_Prod_Data['Model_LGD'],4) == 0.1074, 0.010912, np.where(np.round(LGD_WOE_Prod_Data['Model_LGD'],4) == 0.1821, 0.029987, np.where(np.round(LGD_WOE_Prod_Data['Model_LGD'],4) == 0.2528, 0.056927, np.where(np.round(LGD_WOE_Prod_Data['Model_LGD'],4) == 0.5355, 0.101136, np.nan))))  #unfortunately this is hard-coded due to data availability, but the good thing is that if the numerical model_LGD values change due to model change, then the map results in missing values - which is a good thing to be easily noticed. If hard-coded based on MRS_Bin, then it is not easy to be noticed and quite dangerous to assign outdated values. SO this is a safe hard-coding!                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b80c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Loan_Number to integer\n",
    "\n",
    "LGD_WOE_Prod_Data['Loan_Number'] = LGD_WOE_Prod_Data['Loan_Number'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07d446",
   "metadata": {},
   "source": [
    "## Double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22c52774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by MRS_Bin_LGD, calculate the min and max of Mapped_LGD and Model_LGD:\n",
      "  MRS_Bin_LGD Mapped_LGD           Model_LGD          \n",
      "                     min       max       min       max\n",
      "0      Pool 1   0.010912  0.010912  0.107376  0.107376\n",
      "1      Pool 2   0.029987  0.029987  0.182108  0.182108\n",
      "2      Pool 3   0.056927  0.056927  0.252839  0.252839\n",
      "3      Pool 4   0.101136  0.101136  0.535503  0.535503\n"
     ]
    }
   ],
   "source": [
    "# Group by MRS_Bin_LGD, calculate the min and max of Mapped_LGD and Model_LGD\n",
    "\n",
    "print('Grouped by MRS_Bin_LGD, calculate the min and max of Mapped_LGD and Model_LGD:')\n",
    "\n",
    "print(LGD_WOE_Prod_Data.groupby(['MRS_Bin_LGD']).agg({'Mapped_LGD': ['min', 'max'], 'Model_LGD': ['min', 'max']}).reset_index().sort_values(by=['MRS_Bin_LGD'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4def40",
   "metadata": {},
   "source": [
    "# Merge All Loaded to Get PD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a85c0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use reduce from functools to merge the following four data sets together on Loan_Number: PD WOE Data with Risk Rating Attribute Data, Consolidated_RESL_Data and PD Scored Data\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "new_pd_data_red = reduce(lambda left, right: pd.merge(left, right, on='Loan_Number', how='left', validate= '1:1'), [PD_WOE_Prod_Data, Risk_Rating_Attribute_Prod_Data, Consolidated_RESL_Data, PD_Scored_Data]) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d53a92c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alt_Prime_Indicator', 'BF_Appr_Prov_Dw', 'BF_LTV_Incl_Parter_Incl_HELOC_FSA_Dw', 'BF_LTV_Tot_Exp_FSA_Dw_WF', 'Beacon_Avg_App_CoApp', 'Beacon_Avg_App_CoApp_WOE', 'Combo_LTV_Insured_Ind_WOE', 'Combo_Province_Metro_Override_WOE', 'Corporate_Applicant_Ind', 'Current_Delinquency_Days', 'Default_Indicator', 'Insured_Ind', 'Loan_Number', 'MRS_Bin_PD', 'Occupancy', 'PD_Post_MOC', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE', 'RemainingPrincipal_Excl_Partner', 'RemainingPrincipal_Tot_Exp', 'SL_Date', 'Sub_Product']\n"
     ]
    }
   ],
   "source": [
    "# print columns in alphabetical order in the new_pd_data_red data\n",
    "\n",
    "print(sorted(new_pd_data_red.columns)) #20250402 George added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb925eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of values of Insured_Ind:\n",
      "Not Insured    28922\n",
      "Insured        24480\n",
      "Name: Insured_Ind, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count values of Insured_Ind. !!!IMportant: Insured_Ind must have values \"Not Insured\" (not \"Uninsured\") to be consistent with model development (scoring will assume these contents - may be OK for now, but safer to be consistent with model development. In contrast, Insured_Class shoudl have values \"Uninsured\" (not \"Not Insured\") because that is assumed in the RWA code\n",
    "\n",
    "print('Count of values of Insured_Ind:')\n",
    "\n",
    "print(new_pd_data_red['Insured_Ind'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc43118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For columns PD_Post_MOC_Pre_Adj and PD_Pre_MOC, if not in the data set, add them with nan #20250402 George added\n",
    "\n",
    "if 'PD_Post_MOC_Pre_Adj' not in new_pd_data_red.columns: #20250402 George added\n",
    "\n",
    "    new_pd_data_red['PD_Post_MOC_Pre_Adj'] = np.nan #20250402 George added\n",
    "\n",
    "if 'PD_Pre_MOC' not in new_pd_data_red.columns: #20250402 George added\n",
    "\n",
    "    new_pd_data_red['PD_Pre_MOC'] = np.nan #20250402 George added\n",
    "\n",
    "\n",
    "# Rename AIRB_PD_Risk_Rating to be MRS_Bin #20250402 George added\n",
    "\n",
    "new_pd_data_red = new_pd_data_red.rename({'AIRB_PD_Risk_Rating':'MRS_Bin'}, axis='columns')  #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78f38a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Checking Default Loans *****************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MRS_Bin_PD Loan_Number PD_Post_MOC          \n",
      "                  nunique         min       max\n",
      "0     Default         368    1.000000  1.000000\n",
      "1  Delinquent         372    0.629118  0.629118\n",
      "2      Pool 1       26281    0.002228  0.002228\n",
      "3      Pool 2       13784    0.003622  0.003622\n",
      "4      Pool 3        5271    0.007377  0.007377\n",
      "5      Pool 4        3037    0.011499  0.011499\n",
      "6      Pool 5        1545    0.019067  0.019067\n",
      "7      Pool 6        1181    0.034554  0.034554\n",
      "8      Pool 7        1563    0.107857  0.107857\n"
     ]
    }
   ],
   "source": [
    "# Group by MRS_Bin_PD, count distinct Loan_Number and min and max of PD_Post_MOC #20250402 George added\n",
    "print('***************Checking Default Loans *****************') #20250402 George added\n",
    "print(new_pd_data_red.groupby(['MRS_Bin_PD'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'PD_Post_MOC': [min, max]})) #20250402 George added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0933d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Dafault Loans\n",
    "\n",
    "# # Remove rows with PD_Post_MOC <=0 or >=1 (defaults) #20250402 George added\n",
    "\n",
    "# new_pd_data_red = new_pd_data_red.loc[(new_pd_data_red['PD_Post_MOC'] > 0) & (new_pd_data_red['PD_Post_MOC'] < 1)] #20250402 George added\n",
    "\n",
    "# # Group by MRS_Bin, count distinct Loan_Number and min and max of PD_Post_MOC #20250402 George added\n",
    "\n",
    "# print('***************After Removing Default Loans*****************') #20250402 George added\n",
    "\n",
    "# print(new_pd_data_red.groupby(['MRS_Bin'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'PD_Post_MOC': [min, max]})) #20250402 George added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a420c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Checking Sub_Product*****************\n",
      "      Sub_Product  Loan_Number\n",
      "0             EQB        43206\n",
      "1  First National         7162\n",
      "2        Paradigm         3034\n"
     ]
    }
   ],
   "source": [
    "# Group by Sub_Product, count distinct Loan_Number \n",
    "\n",
    "print('***************Checking Sub_Product*****************') #20250402 George added\n",
    "\n",
    "print(new_pd_data_red.groupby(['Sub_Product'], as_index=False).agg({'Loan_Number': pd.Series.nunique})) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebddc6e9",
   "metadata": {},
   "source": [
    "# Merge All Loaded to Get LGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "948e7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LGD data\n",
    "\n",
    "new_lgd_data = LGD_WOE_Prod_Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d62e7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns LGD_DT_Adjusted, Segment_Avg_LGD and Base_Line_LGD if they are not in the data set #20250412 George added\n",
    "\n",
    "if 'LGD_DT_Adjusted' not in new_lgd_data.columns: # 20250412 George added\n",
    "    new_lgd_data['LGD_DT_Adjusted'] = np.nan  # 20250412 George added, the numbers are not the latest and this will not be used in the final result\n",
    "\n",
    "if 'Segment_Avg_LGD' not in new_lgd_data.columns: # 20250412 George added, same treatment as RWA for Concentra\n",
    "    new_lgd_data['Segment_Avg_LGD'] = new_lgd_data.loc[:,'Mapped_LGD']\n",
    "\n",
    "if 'Base_Line_LGD' not in new_lgd_data.columns: # 20250412 George added, same treatment as RWA for Concentra\n",
    "    new_lgd_data['Base_Line_LGD'] = new_lgd_data.loc[:,'Mapped_LGD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e783c",
   "metadata": {},
   "source": [
    "# Merge RWA Data Info with PD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "747ffe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = new_pd_data_red[ ['PD_Pre_MOC','PD_Post_MOC_Pre_Adj','PD_Post_MOC'] ].drop_duplicates()\n",
    "\n",
    "rwa_raw_data_1 = pd.merge(rwa_raw_data_0, new_pd_data_red[PD_Cols_to_Keep], how='outer',on=['Loan_Number'], indicator= 'merge_Chenxi_PD')\n",
    "\n",
    "rwa_raw_data_1['merge_Chenxi_PD'] = rwa_raw_data_1['merge_Chenxi_PD'].replace({'left_only': 'Loan in Chenxi only', 'right_only': 'Loan in PD Data only', 'both': 'Loan in both Chenxi and PD'}) #20250403 George added\n",
    "\n",
    "# rwa_raw_data_2 =  rwa_raw_data_1.loc[~rwa_raw_data_1['PD_Pre_MOC'].isnull()] #remove records not existing in Chenxi's data since they cannot be compared\n",
    "\n",
    "rwa_raw_data_2 = rwa_raw_data_1.copy()\n",
    "\n",
    "rwa_raw_data_3 = rwa_raw_data_2.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c48f6",
   "metadata": {},
   "source": [
    "# Merge RWA info with LGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "52382331-c858-42ec-9935-6cf32af56b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rwa_raw_data_4 = pd.merge(rwa_raw_data_3,new_lgd_data[LGD_Cols_to_Keep], how='outer', on= ['Loan_Number'], indicator= 'merge_ChenxiPD_LGD')\n",
    "\n",
    "rwa_raw_data_4['merge_ChenxiPD_LGD'] = rwa_raw_data_4['merge_ChenxiPD_LGD'].replace({'left_only': 'Loan in ChenxiPD only', 'right_only': 'Loan in LGD Data only', 'both': 'Loan in both ChenxiPD and LGD'})\n",
    "\n",
    "\n",
    "# rwa_raw_data_4 = rwa_raw_data_4.rename({'MRS_Bin':'MRS_Bin_LGD','Final_LGD':'Model_LGD'}, axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da01f",
   "metadata": {},
   "source": [
    "# Calculate RWA with 0 Addon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "954f8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Addon to be 0\n",
    "\n",
    "rwa_raw_data_0Addon = rwa_raw_data_4.copy()\n",
    "rwa_raw_data_0Addon['AddOn'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e98f4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(CMHC_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15a8e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Run RWA calculation function\n",
    "\n",
    "[df_out_0Addon, rwa_by_Insured_class_0Addon, rwa_by_MRS_Bin_0Addon, res_data_0Addon]  = Lib_RWA.rwa_calculation(df_input_data = rwa_raw_data_0Addon, lgd_gen_floor = lgd_gen_floor, CMHC_lgd = CMHC_lgd, CMHC_pd = CMHC_pd )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4f467de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print duplicated columns in res_data_0Addon - These are in LGD data set\n",
    "\n",
    "print(res_data_0Addon.columns[res_data_0Addon.columns.duplicated()].tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17380f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to parquet\n",
    "\n",
    "res_data_0Addon.to_parquet(Output_dir +'\\\\'+'eqb_rwa_addon_zero.parquet', index=False)\n",
    "\n",
    "# with pd.ExcelWriter(Output_dir +'\\\\'+'eqb_rwa_addon_zero.xlsx' )as writer:\n",
    "#     res_data_0Addon.to_excel(writer, sheet_name='RWA_data', index=False)\n",
    "#     df_out_0Addon.to_excel(writer, sheet_name=\"RWA\") \n",
    "#     rwa_by_Insured_class_0Addon.to_excel(writer, sheet_name=\"rwa_by_Insured_class\")\n",
    "#     rwa_by_MRS_Bin_0Addon.to_excel(writer, sheet_name=\"rwa_by_MRS_Bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab833aa0",
   "metadata": {},
   "source": [
    "# Get LGD Addon and Calculate RWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5bd4ab4-a458-4cb5-a04b-de2df46e3b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n",
      "c:\\Users\\georgez\\OneDrive - Equitable Bank\\MD_RWA_Impact_Analysis (Joseph)\\SFR\\code\\SFR_PD_Recalibration_2023_Lib.py:1732: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn,**kwargs)\n"
     ]
    }
   ],
   "source": [
    "## retrieve DLGD floor readily available AddOn from Finance Production database\n",
    "# Get max Feedid\n",
    "Server_Finance = 'EQDWP01'  \n",
    "Database_Production = 'ET_Finance_Production'   \n",
    "\n",
    "\n",
    "\n",
    "def sql_max_FeedID( snapshot ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_RE_log' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT max([FeedID]) as max_FeedID\n",
    "       FROM {table}\n",
    "       where Reporting_date =  {snapshot} \n",
    "             \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "Max_Feed_ID= tool.download_from_sql( Server_Finance, Database_Production, sql_max_FeedID( \"'\" + snapshot_date + \"'\" ) )['max_FeedID'][0]\n",
    "\n",
    "def sql_LGD_addon( Max_Feed_ID ):\n",
    "    \n",
    "    table = 'ET_Finance_Production.dbo.tb_X_WoE_LGD_Result' # 20250410 George added\n",
    "\n",
    "    if pd.to_datetime(snapshot_date) <= pd.to_datetime('2024-10-31'):\n",
    "        table = table + '_G2'  # 20250410 George added for Generation 2 model\n",
    "\n",
    "    sql = f'''\n",
    "      SELECT \n",
    "       [LoanNumber]\n",
    "       ,[Add_on_LGD] as AddOn\n",
    "       FROM {table}\n",
    "       where RunID =  {Max_Feed_ID} \n",
    "            '''  \n",
    "    return sql\n",
    "\n",
    "Add_on_LGD= tool.download_from_sql( Server_Finance, Database_Production, sql_LGD_addon(Max_Feed_ID) )\n",
    "\n",
    "Add_on_LGD['LoanNumber'] = Add_on_LGD['LoanNumber'].astype(str).astype(int)\n",
    "\n",
    "rwa_raw_data_TrueAddon = pd.merge(rwa_raw_data_4, Add_on_LGD, how='left', left_on= ['Loan_Number'],right_on=['LoanNumber'])\n",
    "\n",
    "\n",
    "#rwa_raw_data_5['Final_LGD'] = rwa_raw_data_5['Final_LGD_old']\n",
    "#rwa_raw_data_5['PD_Post_MOC'] = rwa_raw_data_5['CalibratedPD_old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bfadc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Run RWA calculation function\n",
    "\n",
    "[df_out, rwa_by_Insured_class, rwa_by_MRS_Bin, res_data]  = Lib_RWA.rwa_calculation(rwa_raw_data_TrueAddon, lgd_gen_floor, CMHC_lgd, CMHC_pd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80935c51",
   "metadata": {},
   "source": [
    "# Sanity Check the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9e22027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot date: 2024-12-31\n",
      "Shape of res_data: (53402, 50)\n",
      "***************Group by Insured_Indicator*****************\n",
      "  Insured_class  Loan_Number           EAD       RWA_new  RWA_Ratio\n",
      "0            CG       4534.0  1.290269e+09  9.586197e+07   0.074296\n",
      "1          CMHC      11040.0  3.061192e+09  5.133710e+07   0.016770\n",
      "2         Sagen       8832.0  2.293171e+09  1.815925e+08   0.079188\n",
      "3     Uninsured      28996.0  1.562863e+10  3.627522e+09   0.232107\n",
      "4         Total      53402.0  2.227326e+10  3.956314e+09   0.177626\n",
      "['AddOn', 'Advance_Amount', 'Alt_Prime_Indicator', 'Appraisal_Bin_WOE', 'BF_LTV_Tot_Exp_FSA_Dw_WF', 'Base_Line_LGD', 'Beacon_Avg_App_CoApp', 'Beacon_Avg_App_CoApp_WOE', 'CalibratedPD', 'Combo_LTV_Insured_Ind_WOE', 'Combo_Province_Metro_Override_WOE', 'Corporate_Applicant_Ind', 'DLGD_floor', 'EAD', 'EAD_DLGD_Modified', 'EAD_Post_CRM', 'Final_LGD', 'Insured_Ind', 'Insured_class', 'LGD_Before_Floors', 'LGD_DT_Adjusted', 'LTV_Bin_WOE', 'LoanNumber', 'Loan_Number', 'MRS_Bin_LGD', 'MRS_Bin_PD', 'Mapped_LGD', 'Maturity_adj', 'Model_LGD_Modified', 'OSFI_LGD_floor', 'Occupancy_WOE', 'Pre_final_LGD', 'Prior_24_Worse_Delinquent_Status_FMT_Adj', 'Prior_24_Worse_Delinquent_Status_FMT_Adj_WOE', 'Province_Foreclosure_WOE', 'RWA_new', 'RWA_standardized', 'RemainingPrincipal_Excl_Partner', 'RemainingPrincipal_Tot_Exp', 'SL_Date', 'Segment_Avg_LGD', 'Years_to_maturity', 'corr_insured', 'corr_uninsured', 'deductible_amount', 'insured_PMI_ratio', 'merge_ChenxiPD_LGD', 'merge_Chenxi_PD', 'risk_weight_insured', 'risk_weight_uninsured']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georgez\\AppData\\Local\\Temp\\ipykernel_8452\\1574102103.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Sumry = Sumry.append(Sumry.sum(numeric_only=True), ignore_index=True) #20250403 George added\n"
     ]
    }
   ],
   "source": [
    "# print snapshot date \n",
    "\n",
    "print('Snapshot date: ' + snapshot_date) #20250403 George added\n",
    "\n",
    "# print the shape of res_data\n",
    "\n",
    "print('Shape of res_data: ' + str(res_data.shape)) #20250403 George added\n",
    "\n",
    "# Group by Insured_Indicator, count number of Loan_Number, sum of EAD and RWA_new\n",
    "\n",
    "print('***************Group by Insured_Indicator*****************') #20250403 George added\n",
    "\n",
    "Sumry = res_data.groupby(['Insured_class'], as_index=False).agg({'Loan_Number': pd.Series.nunique, 'EAD': sum, 'RWA_new': sum}) #20250403 George added\n",
    "\n",
    "# Add a total row to Sumry\n",
    "\n",
    "Sumry = Sumry.append(Sumry.sum(numeric_only=True), ignore_index=True) #20250403 George added\n",
    "Sumry.at[Sumry.index[-1], 'Insured_class'] = 'Total' #20250403 George added\n",
    "\n",
    "# Add a column RWA_Ratio as the ratio of RWA_new and EAD\n",
    "\n",
    "Sumry['RWA_Ratio'] = Sumry['RWA_new'] / Sumry['EAD'] #20250403 George added\n",
    "\n",
    "# print the summary\n",
    "\n",
    "print(Sumry) #20250403 George added\n",
    "\n",
    "# print columns in alphabetical ored\n",
    "\n",
    "print(sorted(res_data.columns)) #20250403 George added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db358899",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c8f9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to Parquet file\n",
    "\n",
    "res_data.to_parquet(Output_dir +'\\\\'+'eqb_rwa_original.parquet', index=False)\n",
    "\n",
    "# with pd.ExcelWriter(Output_dir +'\\\\'+'eqb_rwa_original.xlsx' )as writer:\n",
    "#     res_data.to_excel(writer, sheet_name='RWA_Data', index=False)\n",
    "#     df_out.to_excel(writer, sheet_name=\"RWA\") \n",
    "#     rwa_by_Insured_class.to_excel(writer, sheet_name=\"rwa_by_Insured_class\")\n",
    "#     rwa_by_MRS_Bin.to_excel(writer, sheet_name=\"rwa_by_MRS_Bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Commercial_IFRS9_PD_2024Dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
